apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: pyspark-job
  namespace: default
spec:
  type: Python
  mode: cluster
  image: spark:3.5.3 
  imagePullPolicy: Always
  sparkConf:
    "spark.jars.ivy": "/tmp/ivy"
    "spark.hadoop.fs.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
    "spark.hadoop.fs.AbstractFileSystem.gs.impl": "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
    "spark.hadoop.fs.gs.project.id" : "trading-term"
    "spark.hadoop.google.cloud.auth.service.account.enable": "true"
    "spark.hadoop.google.cloud.auth.service.account.json.keyfile": "/mnt/secrets/gcs-key.json"
  mainApplicationFile: "local:///mnt/spark-apps/analyzer.py"
  sparkVersion: "3.5.3"
  restartPolicy:
    type: Never
  deps:
    jars:
      - https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar
  driver:
    cores: 1
    memory: "512m"
    serviceAccount: spark-operator-spark
    secrets:
      - name: gcs-key
        path: /mnt/secrets
        secretType: GCPServiceAccount
    envVars:
      GCS_PROJECT_ID: trading-term
    configMaps:
      - name: spark-apps
        path: /mnt/spark-apps
  executor:
    cores: 1
    instances: 2
    memory: "512m"
    secrets:
      - name: gcs-key
        path: /mnt/secrets
        secretType: GCPServiceAccount
    envVars:
      GCS_PROJECT_ID: trading-term
    configMaps:
      - name: spark-apps
        path: /mnt/spark-apps
